{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H A $\\alpha$ decomposition evaluation\n",
    "\n",
    "In this notebook we compare results of the new implementation of the\n",
    "H A $\\alpha$ decomposition with the C legacy version of PolSARpro.  \n",
    "It assumes the user has a working installation of PolSARpro and has followed the \n",
    "instructions in the README.md file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "# avoid thread conflicts between numpy and dask\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from polsarpro.io import read_PSP_bin, read_T3\n",
    "from polsarpro.decompositions import h_a_alpha, h_a_alpha_dask\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from spectral.io.envi import save_image\n",
    "\n",
    "# change to your local C-PolSARpro install dir\n",
    "c_psp_dir = \"/home/c_psp/Soft/bin/\"\n",
    "os.environ[\"PATH\"]+=os.pathsep+f\"{c_psp_dir}/data_process_sngl/\"\n",
    "os.environ[\"PATH\"]+=os.pathsep+f\"{c_psp_dir}/data_convert/\"\n",
    "\n",
    "# change to your data paths\n",
    "input_test_dir = Path(\"/data/psp/input/h_a_alpha_decomposition/\")\n",
    "# output_test_dir = Path(\"/data/res/freeman_cpsp\")\n",
    "output_test_dir = Path(\"/data/res/h_a_alpha_cpsp\")\n",
    "# output_test_dir = Path(\"/data/psp/output/freeman_decomposition/out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the C-version on some test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polsarpro.devtools import parse_psp_parameter_string\n",
    "import os\n",
    "# fl1: alpha, beta, delta, lambda\n",
    "# fl2: lambda\n",
    "# fl3: alpha\n",
    "# fl4: entropy \n",
    "# fl5: anisotropy\n",
    "# fl6-9 combinations\n",
    "\n",
    "input_str= f\"\"\"id: {input_test_dir} \n",
    "od: {output_test_dir}\n",
    "iodf: T3\n",
    "nwr: 7\n",
    "nwc: 7\n",
    "ofr: 0\n",
    "ofc: 0\n",
    "fnr: 18432\n",
    "fnc: 1248\n",
    "fl1: 1\n",
    "fl2: 1\n",
    "fl3: 1\n",
    "fl4: 1\n",
    "fl5: 1\n",
    "fl6: 0\n",
    "fl7: 0\n",
    "fl8: 0\n",
    "fl9: 0\n",
    "errf: /tmp/MemoryAllocError.txt\n",
    "mask: {input_test_dir}/mask_valid_pixels.bin\n",
    "\"\"\"\n",
    "result = parse_psp_parameter_string(input_str)\n",
    "os.system(f\"h_a_alpha_decomposition.exe {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load coherency matrices and C-PSP outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T3 = read_T3(input_test_dir)\n",
    "\n",
    "out_names = [\"entropy\", \"anisotropy\", \"alpha\", \"beta\", \"delta\", \"gamma\", \"lambda\"]\n",
    "out_c = {}\n",
    "\n",
    "for name in out_names:\n",
    "    file_name = output_test_dir / f\"{name}.bin\"\n",
    "    out_c[name] = read_PSP_bin(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the numpy implementation (single-thread, only for reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = (\"entropy\", \"anisotropy\", \"alpha\", \"beta\", \"delta\", \"gamma\", \"lambda\")\n",
    "out_np = h_a_alpha(T3, \"T3\", boxcar_size=[7, 7], flags=flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the dask implementation (multi-thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = (\"entropy\", \"anisotropy\", \"alpha\", \"beta\", \"delta\", \"gamma\", \"lambda\")\n",
    "out_da = h_a_alpha_dask(T3, \"T3\", boxcar_size=[7, 7], flags=flags)\n",
    "\n",
    "# write outputs\n",
    "for name in out_da.keys():\n",
    "    save_image(hdr_file=output_test_dir / f\"{name}_py.hdr\", image=out_da[name], force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in out_names:\n",
    "    var_c = out_c[var]\n",
    "    var_da = out_da[var]\n",
    "    relerr = np.nanmean(((np.abs(var_da - var_c) / np.abs(var_c + var_da))))\n",
    "    print(f\"Variable {var}\")\n",
    "    print(f\"Relative error between C and python: {relerr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in out_names:\n",
    "    var_np = out_np[var]\n",
    "    var_da = out_da[var]\n",
    "    err = np.nanmean(var_da - var_np)\n",
    "    print(f\"Variable {var}\")\n",
    "    print(f\"Error between dask and numpy: {err}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
